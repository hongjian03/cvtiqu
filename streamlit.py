import streamlit as st
import json
import os
import asyncio
from pathlib import Path
from processor import SimpleProcessor
from llm_processor import LLMProcessor
import tempfile
from qs_usnews_school_dict import qs_school_ranking, usnews_school_ranking
from test_llm import calculate_student_tags, enrich_school_rankings

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="ç®€å†å’ŒOfferåˆ†æå·¥å…·",
    page_icon="ğŸ“„",
    layout="wide"
)

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if 'resume_prompt' not in st.session_state:
    llm_processor = LLMProcessor()
    st.session_state.resume_prompt = llm_processor._get_resume_prompt("")
    st.session_state.offer_prompt = llm_processor._get_offer_prompt("")

# åˆå§‹åŒ–å¤„ç†å™¨
@st.cache_resource
def get_processor():
    return SimpleProcessor()

@st.cache_resource
def get_llm_processor():
    llm_processor = LLMProcessor(
        api_key=st.secrets["OPENAI_API_KEY"],
        api_base=st.secrets["OPENAI_API_BASE"],
        model_name=st.secrets["OPENAI_MODEL"]
    )
    # ä½¿ç”¨ä¼šè¯çŠ¶æ€ä¸­çš„æç¤ºè¯
    llm_processor.resume_prompt = st.session_state.resume_prompt
    llm_processor.offer_prompt = st.session_state.offer_prompt
    return llm_processor

# ä¸»é¡µé¢
def main_page():
    langsmith_api_key = st.secrets["LANGCHAIN_API_KEY"]
    os.environ["LANGCHAIN_TRACING_V2"] = "true"
    os.environ["LANGCHAIN_API_KEY"] = langsmith_api_key
    os.environ["LANGCHAIN_PROJECT"] = "ç®€å†å’ŒOfferåˆ†æå·¥å…·"
    st.title("ğŸ“„ ç®€å†å’ŒOfferåˆ†æå·¥å…·")
    
    # åˆ›å»ºä¸¤åˆ—å¸ƒå±€
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ä¸Šä¼ ç®€å†æ–‡ä»¶")
        resume_file = st.file_uploader("é€‰æ‹©PDFæ ¼å¼çš„ç®€å†æ–‡ä»¶", type=["pdf"], key="resume")
        
    with col2:
        st.subheader("ä¸Šä¼ Offeræ–‡ä»¶")
        offer_files = st.file_uploader("é€‰æ‹©PDFæ ¼å¼çš„Offeræ–‡ä»¶", type=["pdf"], key="offer", accept_multiple_files=True)
    
    # åˆ†ææŒ‰é’®
    if st.button("å¼€å§‹åˆ†æ", type="primary"):
        if resume_file is None and not offer_files:
            st.error("è¯·è‡³å°‘ä¸Šä¼ ä¸€ä¸ªæ–‡ä»¶è¿›è¡Œåˆ†æ")
            return
        st.write(f"ç®€å†æç¤ºè¯ï¼š{st.session_state.resume_prompt}")
        st.write(f"Offeræç¤ºè¯ï¼š{st.session_state.offer_prompt}")
        with st.spinner("æ­£åœ¨åˆ†æä¸­..."):
            processor = get_processor()
            llm_processor = get_llm_processor()
            
            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
            with tempfile.TemporaryDirectory() as temp_dir:
                results = {}
                
                # å¤„ç†ç®€å†
                if resume_file is not None:
                    resume_path = os.path.join(temp_dir, "resume.pdf")
                    with open(resume_path, "wb") as f:
                        f.write(resume_file.getvalue())
                    
                    # æå–æ–‡æœ¬
                    resume_result = processor.process_resume(resume_path)
                    if resume_result["success"]:
                        # ä½¿ç”¨LLMåˆ†æ
                        resume_analysis = llm_processor.analyze_resume(resume_result["content"])
                        results["resume_analysis"] = resume_analysis
                    else:
                        st.error(f"ç®€å†åˆ†æå¤±è´¥: {resume_result['error']}")
                
                # å¤„ç†Offer
                if offer_files:
                    offer_paths = []
                    for i, offer_file in enumerate(offer_files):
                        offer_path = os.path.join(temp_dir, f"offer_{i}.pdf")
                        with open(offer_path, "wb") as f:
                            f.write(offer_file.getvalue())
                        offer_paths.append(offer_path)
                    
                    # æå–æ–‡æœ¬ - ä½¿ç”¨æ–‡ä»¶è·¯å¾„åˆ—è¡¨è°ƒç”¨process_offer
                    offer_results = processor.process_offer(offer_paths)
                    offer_texts = []
                    
                    for offer_result in offer_results:
                        if offer_result["success"]:
                            offer_texts.append(offer_result["content"])
                        else:
                            st.error(f"Offeråˆ†æå¤±è´¥: {offer_result['error']}")
                    
                    if offer_texts:
                        # ä½¿ç”¨LLMåˆ†æ
                        api_results = asyncio.run(llm_processor.process_documents(
                            resume_text=resume_result["content"] if resume_file else "",
                            offer_texts=offer_texts
                        ))
                        
                        # ç¡®ä¿offer_analysesæ˜¯ä¸€ä¸ªåˆ—è¡¨
                        if isinstance(api_results, dict):
                            offer_analyses = api_results.get("offer_analyses", [])
                        else:
                            offer_analyses = []
                        
                        # å¤„ç†å¯èƒ½çš„æ ¼å¼ä¸ä¸€è‡´æƒ…å†µ
                        processed_offer_analyses = []
                        for offer in offer_analyses:
                            # æ£€æŸ¥offeræ˜¯å¦ä¸ºå­—å…¸ä¸”åŒ…å«admissionså­—æ®µ
                            if isinstance(offer, dict) and "admissions" in offer:
                                processed_offer_analyses.append(offer)
                            # å¦‚æœofferæ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•è§£æä¸ºJSON
                            elif isinstance(offer, str):
                                try:
                                    offer_dict = json.loads(offer)
                                    processed_offer_analyses.append(offer_dict)
                                except:
                                    # å¦‚æœæ— æ³•è§£æä¸ºJSONï¼ŒåŒ…è£…ä¸ºç»Ÿä¸€æ ¼å¼
                                    processed_offer_analyses.append({"admissions": []})
                            else:
                                # ç¡®ä¿æ¯ä¸ªofferè‡³å°‘æœ‰ä¸€ä¸ªç©ºçš„admissionsåˆ—è¡¨
                                processed_offer_analyses.append({"admissions": []})
                        
                        results["offer_analyses"] = processed_offer_analyses
                
                # è®¡ç®—æ ‡ç­¾å’Œä¸°å¯Œå­¦æ ¡æ’å
                if results:
                    # ä¸°å¯Œå­¦æ ¡æ’å
                    try:
                        enrich_school_rankings(results)
                    except Exception as e:
                        st.warning(f"ä¸°å¯Œå­¦æ ¡æ’åæ—¶å‡ºé”™: {str(e)}")
                        
                    # è®¡ç®—æ ‡ç­¾
                    try:
                        tags = calculate_student_tags(results)
                        if tags:
                            results["tags"] = tags
                    except Exception as e:
                        st.warning(f"è®¡ç®—æ ‡ç­¾æ—¶å‡ºé”™: {str(e)}")
                    # æ˜¾ç¤ºç»“æœ
                    st.subheader("åˆ†æç»“æœ")
                    st.json(results)
                    
                    # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
                    with open("combined_analysis.json", "w", encoding="utf-8") as f:
                        json.dump(results, f, ensure_ascii=False, indent=2)
                    st.success("åˆ†æç»“æœå·²ä¿å­˜åˆ° combined_analysis.json")

# æç¤ºè¯ç®¡ç†é¡µé¢
def prompts_page():
    st.title("ğŸ”§ æç¤ºè¯ç®¡ç†")
    
    # ç®€å†åˆ†ææç¤ºè¯
    st.subheader("ç®€å†åˆ†ææç¤ºè¯")
    resume_prompt = st.text_area(
        "ç®€å†åˆ†ææç¤ºè¯",
        value=st.session_state.resume_prompt,
        height=200,
        key="resume_prompt_input"
    )
    
    # Offeråˆ†ææç¤ºè¯
    st.subheader("Offeråˆ†ææç¤ºè¯")
    offer_prompt = st.text_area(
        "Offeråˆ†ææç¤ºè¯",
        value=st.session_state.offer_prompt,
        height=200,
        key="offer_prompt_input"
    )
    
    # æ›´æ–°æŒ‰é’®
    if st.button("æ›´æ–°æç¤ºè¯", type="primary"):
        # æ›´æ–°ä¼šè¯çŠ¶æ€ä¸­çš„æç¤ºè¯
        st.session_state.resume_prompt = resume_prompt
        st.session_state.offer_prompt = offer_prompt
        st.success("æç¤ºè¯å·²æ›´æ–°ï¼")
        
        # é‡æ–°åˆå§‹åŒ–LLMå¤„ç†å™¨ä»¥åº”ç”¨æ–°çš„æç¤ºè¯
        st.cache_resource.clear()
        get_llm_processor()

# ä¸»ç¨‹åº
def main():
    # åˆ›å»ºæ ‡ç­¾é¡µ
    tab1, tab2 = st.tabs(["ğŸ“„ æ–‡ä»¶åˆ†æ", "ğŸ”§ æç¤ºè¯ç®¡ç†"])
    
    with tab1:
        main_page()
    
    with tab2:
        prompts_page()

if __name__ == "__main__":
    main()
