import streamlit as st
import json
import os
import asyncio
from pathlib import Path
from processor import SimpleProcessor
from llm_processor import LLMProcessor
import tempfile
from qs_usnews_school_dict import qs_school_ranking, usnews_school_ranking
from test_llm import calculate_student_tags, enrich_school_rankings

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="ç®€å†å’ŒOfferåˆ†æå·¥å…·",
    page_icon="ğŸ“„",
    layout="wide"
)

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if 'resume_prompt' not in st.session_state:
    llm_processor = LLMProcessor()
    # å­˜å‚¨åŸå§‹çš„æç¤ºè¯æ¨¡æ¿ï¼Œè€Œä¸æ˜¯å·²ç»å¤„ç†è¿‡çš„æç¤ºè¯
    st.session_state.resume_prompt = """You are an expert at extracting information from resumes.
        
Given the text content of a resume, extract and format the following information as a JSON object.
You must respond with ONLY the JSON object, no other text.

{
    "studentName": "åªå†™å§“æ°é¦–å­—æ¯+åŒå­¦ï¼Œæ¯”å¦‚'ZåŒå­¦'",
    "education": {
        "institution": "å­¦æ ¡åç§°(ç”¨ä¸­æ–‡,å¦‚:'åŒ—äº¬å¤§å­¦')",
        "major": "ä¸“ä¸šåç§°(ç”¨ä¸­æ–‡,å¦‚:'è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯')",
        "gpaValue": "GPAæˆç»©(æ•°å­—æ ¼å¼,å¦‚:3.38)",
        "gpaOriginal": "åŸå§‹GPAæ ¼å¼(å¦‚:'3.38/4.0')",
         "institutionType": "é™¢æ ¡ç±»å‹(æšä¸¾å€¼:'DOMESTIC_C9','DOMESTIC_985','DOMESTIC_211','DOMESTIC_COOPERATIVE','OVERSEAS_UNIVERSITY','DOMESTIC_UNIVERSITY','HONGKONG_MACAO_TAIWAN', 'OVERSEAS_K12','DOMESTIC_K12')"
    },
    "testScores": [ 
        {
            "testType": "LANGUAGE or STANDARDIZED or OTHER",
            "testName": "è€ƒè¯•åç§°",
            "testScore": "æ€»åˆ†",
            "detailScores": {
                "åˆ†é¡¹åç§°": "åˆ†é¡¹åˆ†æ•°"
            }
        }
    ],
    "experiences": [
        {
            "type": "INTERNSHIP/RESEARCH/COMPETITION/OTHER",
            "description": "ä¸€å¥è¯æ¦‚è¿°ç»å†ç±»å‹å’Œæ€§è´¨",
            "organization": "æœºæ„æ¡£æ¬¡æè¿°",
            "role": "æ‹…ä»»è§’è‰²(å¿…å¡«,å¦‚æœç®€å†ä¸­æœªæ˜ç¡®è¯´æ˜,è¯·æ ¹æ®å·¥ä½œå†…å®¹æ¨æ–­)",
            "duration": "æŒç»­æ—¶é—´",
            "achievement": "æˆæœæè¿°"
        }
    ]
}

Resume text:
{resume_text}

Please return only the JSON format analysis result without additional explanation text.
"""
    st.session_state.offer_prompt = """You are an expert at extracting information from university admission offer letters and gathering additional program information.
        
Follow these steps exactly:
1. First analyze the offer letter text to extract basic information
2. Extract rankings if mentioned in the text
3. Combine all information into a JSON response

The response must be a valid JSON object with this exact structure:
{
    "admissions": [
        {
            "school": "the full university name in English",
            "country": "å­¦æ ¡æ‰€åœ¨å›½å®¶(ç”¨ä¸­æ–‡,å¦‚:'ç¾å›½'/'è‹±å›½'/'æ–°åŠ å¡')",
            "program": "the full program name in English",
            "majorCategory": "ä¸“ä¸šç±»åˆ«(ç”¨ä¸­æ–‡,å¦‚:'è®¡ç®—æœºç§‘å­¦'/'å·¥å•†ç®¡ç†'/'æ•°æ®ç§‘å­¦')",
            "degreeType": "UNDERGRADUATE/MASTER/PHD/OTHER",
            "rankingType": "å¿…å¡«ï¼Œæ’åç±»å‹(ç¾å›½å­¦æ ¡å¡«å†™'US News',å…¶ä»–å­¦æ ¡å¡«å†™'QS')",
            "rankingValue": "",
            "rankingTier": "",
            "enrollmentSeason": "å…¥å­¦å­£èŠ‚(å¦‚ï¼šSpring/Fall/Summer/Winter 2025)",
            "hasScholarship": true/false,
            "scholarshipAmount": "å¥–å­¦é‡‘é‡‘é¢(åŒ…å«å¹´åº¦ä¿¡æ¯,å¦‚:'$7,000/year'/'ï¿¥50,000/semester')",
            "scholarshipNote": "é¢å¤–çš„å¥–å­¦é‡‘è¯´æ˜(å¦‚è·å¥–åŸå› ã€ç»­æœŸæ¡ä»¶ç­‰)"
        }
    ]
}

Offer letter text:
{offer_text}

Please return only the JSON format analysis result without additional explanation text.
"""

# åˆå§‹åŒ–å¤„ç†å™¨
@st.cache_resource
def get_processor():
    return SimpleProcessor()

@st.cache_resource
def get_llm_processor():
    try:
        # ä½¿ç”¨Streamlit Secretsåˆ›å»ºLLMå¤„ç†å™¨
        llm_processor = LLMProcessor(
            api_key=st.secrets["OPENAI_API_KEY"],
            api_base=st.secrets["OPENAI_API_BASE"],
            model_name=st.secrets["OPENAI_MODEL"]
        )
        
        # ç¡®ä¿ä¼šè¯çŠ¶æ€ä¸­çš„æç¤ºè¯å·²åˆå§‹åŒ–
        if 'resume_prompt' not in st.session_state:
            st.warning("æç¤ºè¯å°šæœªåˆå§‹åŒ–ï¼Œæ­£åœ¨ä½¿ç”¨é»˜è®¤æç¤ºè¯")
            return llm_processor
        
        # ä½¿ç”¨ä¼šè¯çŠ¶æ€ä¸­çš„æç¤ºè¯
        llm_processor.resume_prompt = st.session_state.resume_prompt
        llm_processor.offer_prompt = st.session_state.offer_prompt
        
        return llm_processor
    except Exception as e:
        st.error(f"åˆå§‹åŒ–LLMå¤„ç†å™¨æ—¶å‡ºé”™: {str(e)}")
        # è¿”å›ä¸€ä¸ªå¤‡ç”¨å¤„ç†å™¨
        return LLMProcessor()

# ä¸»é¡µé¢
def main_page():
    langsmith_api_key = st.secrets["LANGCHAIN_API_KEY"]
    os.environ["LANGCHAIN_TRACING_V2"] = "true"
    os.environ["LANGCHAIN_API_KEY"] = langsmith_api_key
    os.environ["LANGCHAIN_PROJECT"] = "ç®€å†å’ŒOfferåˆ†æå·¥å…·"
    st.title("ğŸ“„ ç®€å†å’ŒOfferåˆ†æå·¥å…·")
    
    # åˆ›å»ºä¸¤åˆ—å¸ƒå±€
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ä¸Šä¼ ç®€å†æ–‡ä»¶")
        resume_file = st.file_uploader("é€‰æ‹©PDFæ ¼å¼çš„ç®€å†æ–‡ä»¶", type=["pdf"], key="resume")
        
    with col2:
        st.subheader("ä¸Šä¼ Offeræ–‡ä»¶")
        offer_files = st.file_uploader("é€‰æ‹©PDFæ ¼å¼çš„Offeræ–‡ä»¶", type=["pdf"], key="offer", accept_multiple_files=True)
    
    # åˆ†ææŒ‰é’®
    if st.button("å¼€å§‹åˆ†æ", type="primary"):
        if resume_file is None and not offer_files:
            st.error("è¯·è‡³å°‘ä¸Šä¼ ä¸€ä¸ªæ–‡ä»¶è¿›è¡Œåˆ†æ")
            return
        
        # æ˜¾ç¤ºæç¤ºè¯ä¿¡æ¯ï¼ˆè°ƒè¯•ç”¨ï¼‰
        with st.expander("æŸ¥çœ‹æç¤ºè¯é…ç½®ï¼ˆè°ƒè¯•ç”¨ï¼‰"):
            st.text("ç®€å†æç¤ºè¯:")
            st.code(st.session_state.resume_prompt)
            st.text("Offeræç¤ºè¯:")
            st.code(st.session_state.offer_prompt)
        
        with st.spinner("æ­£åœ¨åˆ†æä¸­..."):
            processor = get_processor()
            llm_processor = get_llm_processor()
            
            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
            with tempfile.TemporaryDirectory() as temp_dir:
                results = {}
                
                # å¤„ç†ç®€å†
                if resume_file is not None:
                    resume_path = os.path.join(temp_dir, "resume.pdf")
                    with open(resume_path, "wb") as f:
                        f.write(resume_file.getvalue())
                    
                    # æå–æ–‡æœ¬
                    resume_result = processor.process_resume(resume_path)
                    if resume_result["success"]:
                        # ä½¿ç”¨LLMåˆ†æ
                        resume_analysis = llm_processor.analyze_resume(resume_result["content"])
                        results["resume_analysis"] = resume_analysis
                    else:
                        st.error(f"ç®€å†åˆ†æå¤±è´¥: {resume_result['error']}")
                
                # å¤„ç†Offer
                if offer_files:
                    offer_paths = []
                    for i, offer_file in enumerate(offer_files):
                        offer_path = os.path.join(temp_dir, f"offer_{i}.pdf")
                        with open(offer_path, "wb") as f:
                            f.write(offer_file.getvalue())
                        offer_paths.append(offer_path)
                    
                    # æå–æ–‡æœ¬ - ä½¿ç”¨æ–‡ä»¶è·¯å¾„åˆ—è¡¨è°ƒç”¨process_offer
                    offer_results = processor.process_offer(offer_paths)
                    offer_texts = []
                    
                    for offer_result in offer_results:
                        if offer_result["success"]:
                            offer_texts.append(offer_result["content"])
                        else:
                            st.error(f"Offeråˆ†æå¤±è´¥: {offer_result['error']}")
                    
                    if offer_texts:
                        # ä½¿ç”¨LLMåˆ†æ
                        api_results = asyncio.run(llm_processor.process_documents(
                            resume_text=resume_result["content"] if resume_file else "",
                            offer_texts=offer_texts
                        ))
                        
                        # ç¡®ä¿offer_analysesæ˜¯ä¸€ä¸ªåˆ—è¡¨
                        if isinstance(api_results, dict):
                            offer_analyses = api_results.get("offer_analyses", [])
                        else:
                            offer_analyses = []
                        
                        # å¤„ç†å¯èƒ½çš„æ ¼å¼ä¸ä¸€è‡´æƒ…å†µ
                        processed_offer_analyses = []
                        for offer in offer_analyses:
                            # æ£€æŸ¥offeræ˜¯å¦ä¸ºå­—å…¸ä¸”åŒ…å«admissionså­—æ®µ
                            if isinstance(offer, dict) and "admissions" in offer:
                                processed_offer_analyses.append(offer)
                            # å¦‚æœofferæ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•è§£æä¸ºJSON
                            elif isinstance(offer, str):
                                try:
                                    offer_dict = json.loads(offer)
                                    processed_offer_analyses.append(offer_dict)
                                except:
                                    # å¦‚æœæ— æ³•è§£æä¸ºJSONï¼ŒåŒ…è£…ä¸ºç»Ÿä¸€æ ¼å¼
                                    processed_offer_analyses.append({"admissions": []})
                            else:
                                # ç¡®ä¿æ¯ä¸ªofferè‡³å°‘æœ‰ä¸€ä¸ªç©ºçš„admissionsåˆ—è¡¨
                                processed_offer_analyses.append({"admissions": []})
                        
                        results["offer_analyses"] = processed_offer_analyses
                
                # è®¡ç®—æ ‡ç­¾å’Œä¸°å¯Œå­¦æ ¡æ’å
                if results:
                    # ä¸°å¯Œå­¦æ ¡æ’å
                    try:
                        enrich_school_rankings(results)
                    except Exception as e:
                        st.warning(f"ä¸°å¯Œå­¦æ ¡æ’åæ—¶å‡ºé”™: {str(e)}")
                        
                    # è®¡ç®—æ ‡ç­¾
                    try:
                        tags = calculate_student_tags(results)
                        if tags:
                            results["tags"] = tags
                    except Exception as e:
                        st.warning(f"è®¡ç®—æ ‡ç­¾æ—¶å‡ºé”™: {str(e)}")
                    # æ˜¾ç¤ºç»“æœ
                    st.subheader("åˆ†æç»“æœ")
                    st.json(results)
                    
                    # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
                    with open("combined_analysis.json", "w", encoding="utf-8") as f:
                        json.dump(results, f, ensure_ascii=False, indent=2)
                    st.success("åˆ†æç»“æœå·²ä¿å­˜åˆ° combined_analysis.json")

# æç¤ºè¯ç®¡ç†é¡µé¢
def prompts_page():
    st.title("ğŸ”§ æç¤ºè¯ç®¡ç†")
    
    # ç®€å†åˆ†ææç¤ºè¯
    st.subheader("ç®€å†åˆ†ææç¤ºè¯")
    resume_prompt = st.text_area(
        "ç®€å†åˆ†ææç¤ºè¯",
        value=st.session_state.resume_prompt,
        height=200,
        key="resume_prompt_input"
    )
    
    # Offeråˆ†ææç¤ºè¯
    st.subheader("Offeråˆ†ææç¤ºè¯")
    offer_prompt = st.text_area(
        "Offeråˆ†ææç¤ºè¯",
        value=st.session_state.offer_prompt,
        height=200,
        key="offer_prompt_input"
    )
    
    # æç¤ºç”¨æˆ·æ·»åŠ å ä½ç¬¦
    st.info("è¯·ç¡®ä¿ç®€å†æç¤ºè¯ä¸­åŒ…å« {resume_text} å ä½ç¬¦ï¼ŒOfferæç¤ºè¯ä¸­åŒ…å« {offer_text} å ä½ç¬¦ï¼Œç”¨äºæ›¿æ¢å®é™…çš„æ–‡æœ¬å†…å®¹ã€‚")
    
    # æ›´æ–°æŒ‰é’®
    if st.button("æ›´æ–°æç¤ºè¯", type="primary"):
        # æ£€æŸ¥å ä½ç¬¦æ˜¯å¦å­˜åœ¨
        if "{resume_text}" not in resume_prompt:
            st.warning("è­¦å‘Šï¼šç®€å†æç¤ºè¯ä¸­æœªæ‰¾åˆ° {resume_text} å ä½ç¬¦ï¼Œç³»ç»Ÿå°†è‡ªåŠ¨åœ¨æç¤ºè¯æœ«å°¾æ·»åŠ ç®€å†æ–‡æœ¬ã€‚")
        
        if "{offer_text}" not in offer_prompt:
            st.warning("è­¦å‘Šï¼šOfferæç¤ºè¯ä¸­æœªæ‰¾åˆ° {offer_text} å ä½ç¬¦ï¼Œç³»ç»Ÿå°†è‡ªåŠ¨åœ¨æç¤ºè¯æœ«å°¾æ·»åŠ Offeræ–‡æœ¬ã€‚")
        
        # æ›´æ–°ä¼šè¯çŠ¶æ€ä¸­çš„æç¤ºè¯
        st.session_state.resume_prompt = resume_prompt
        st.session_state.offer_prompt = offer_prompt
        st.success("æç¤ºè¯å·²æ›´æ–°ï¼")
        
        # é‡æ–°åˆå§‹åŒ–LLMå¤„ç†å™¨ä»¥åº”ç”¨æ–°çš„æç¤ºè¯
        st.cache_resource.clear()
        get_llm_processor()

# ä¸»ç¨‹åº
def main():
    # åˆ›å»ºæ ‡ç­¾é¡µ
    tab1, tab2 = st.tabs(["ğŸ“„ æ–‡ä»¶åˆ†æ", "ğŸ”§ æç¤ºè¯ç®¡ç†"])
    
    with tab1:
        main_page()
    
    with tab2:
        prompts_page()

if __name__ == "__main__":
    main()
